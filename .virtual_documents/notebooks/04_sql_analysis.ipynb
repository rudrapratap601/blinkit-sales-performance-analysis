


# Environment
from dotenv import load_dotenv
import os

# Database
from sqlalchemy import create_engine, text
from urllib.parse import quote_plus

# Data
import pandas as pd
import numpy as np





load_dotenv("../.env")





user = os.getenv("DB_USER")
password = quote_plus(os.getenv("DB_PASSWORD"))
host = os.getenv("DB_HOST")
port = os.getenv("DB_PORT")

engine = create_engine(
    f"mysql+pymysql://{user}:{password}@{host}:{port}"
)

with engine.connect() as conn:
    print("Connected Successfully!")





with engine.begin() as conn:
    conn.execute(
        text("CREATE DATABASE IF NOT EXISTS blinkit_db")
    )
    
print("Database created (or already exists)!")





engine = create_engine(
    f"mysql+pymysql://{user}:{password}@{host}:{port}/blinkit_db"
)

print("Switched to blinkit_db successfully!")





DATA_PATH = r"C:\Users\rudra\OneDrive\Documents\GitHub\blinkit-end-to-end-data-analysis\data\relational"

files = {
    "customer_feedback": "blinkit_customer_feedback.csv",
    "customers": "blinkit_customers.csv",
    "order_items": "blinkit_order_items.csv",
    "orders": "blinkit_orders.csv",
    "products": "blinkit_products.csv"
}

for table_name, file_name in files.items():
    df = pd.read_csv(f"{DATA_PATH}\\{file_name}")
    df.to_sql(table_name, engine, if_exists="replace", index=False)
    print(f"{table_name}: {df.shape[0]} rows inserted")



















